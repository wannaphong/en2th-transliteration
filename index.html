<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>English to Thai Transliteration</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; max-width: 600px; margin: 2rem auto; padding: 0 1rem; }
        input, button { padding: 12px; font-size: 1rem; border-radius: 4px; border: 1px solid #ccc; }
        input { width: 60%; }
        button { background: #007bff; color: white; border: none; cursor: pointer; }
        button:hover { background: #0056b3; }
        
        .output-box { margin-top: 20px; padding: 15px; background: #f8f9fa; border-radius: 8px; }
        .label { font-size: 0.8rem; color: #666; text-transform: uppercase; letter-spacing: 1px; margin-bottom: 5px; }
        .value { font-size: 1.5rem; color: #333; font-weight: bold; }
        
        /* Syllable badge style */
        .syllable { display: inline-block; background: #e2e6ea; color: #333; padding: 2px 8px; border-radius: 12px; font-size: 1rem; margin-right: 5px; border: 1px solid #ced4da; }
        .loading { color: #888; font-size: 0.9rem; }
    </style>
</head>
<body>

    <h2>EN-TH Transliteration</h2>
    
    <div>
        <input type="text" id="inputText" placeholder="e.g. computer" onkeydown="if(event.key==='Enter') runInference()">
        <button onclick="runInference()">Convert</button>
    </div>

    <div class="output-box">
        <div class="label">Tokens (Syllables)</div>
        <div id="syllableResult" class="value" style="font-size: 1rem; min-height: 1.5rem;">-</div>
    </div>

    <div class="output-box">
        <div class="label">Thai Prediction</div>
        <div id="result" class="value" style="color: #007bff;">-</div>
    </div>
    
    <div id="status" class="loading" style="margin-top:10px;">Loading models...</div>

    <script>
        // --- 1. CONFIGURATION ---
        const VOCAB_DATA = {
            "input_char2idx": {
                '<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3,
                'a': 4, 'c': 5, 't': 6, 'i': 7, 'o': 8, 'n': 9, 'v': 10, 'e': 11,
                'd': 12, 'p': 13, 'r': 14, 'l': 15, 'b': 16, 'u': 17, 'm': 18, 'h': 19,
                'g': 20, 's': 21, 'k': 22, 'y': 23, 'x': 24, 'f': 25, 'w': 26, 'j': 27,
                'z': 28, 'q': 29, '-': 30, ' ': 31, 'é': 32, "'": 33, 'ฺ': 34, 'è': 35,
                '岸': 36, '田': 37, '文': 38, '雄': 39, '.': 40, '1': 41, '7': 42, '3': 43,
                '9': 44, '–': 45
            },
            "target_idx2char": {
                "0": "<PAD>", "1": "<SOS>", "2": "<EOS>", "3": "<UNK>",
                "4": "แ", "5": "อ", "6": "ค", "7": "ช", "8": "ั", "9": "่", "10": "น",
                "11": "ท", "12": "ี", "13": "ฟ", "14": "ะ", "15": "ด", "16": "ป", "17": "เ",
                "18": "ต", "19": "ร", "20": "์", "21": "ล", "22": "บ", "23": "้", "24": "ม",
                "25": "ก", "26": "ฮ", "27": "า", "28": "ิ", "29": "ึ", "30": "พ", "31": "ส",
                "32": "ซ", "33": "โ", "34": "็", "35": "ง", "36": "ุ", "37": "๊", "38": "ู",
                "39": "ว", "40": "ไ", "41": "ย", "42": "จ", "43": "ห", "44": "ศ", "45": "ธ",
                "46": "ฤ", "47": "ษ", "48": "ฎ", "49": "๋", "50": " ", "51": "ำ", "52": "ถ",
                "53": "ฉ", "54": "1", "55": "ญ", "56": "-", "57": "ฃ", "58": "9", "59": "3",
                "60": "ฌ", "61": "y", "62": "l", "63": "o", "64": "n", "65": "ข", "66": "ฝ"
            }
        };

        const MAX_LEN = 20;
        let encSession, decSession;

        // --- 2. SYLLABLE TOKENIZER ---
        function tokenizeSyllables(word) {
            word = word.toLowerCase();
            if (word.length <= 3) return [word];

            // Handle 'le' at end (apple -> ap-ple)
            if (word.slice(-2) === 'le' && !['a','e','i','o','u'].includes(word.slice(-3, -2))) {
                const main = word.slice(0, -2);
                return [...tokenizeSyllables(main), 'le'];
            }

            // Regex heuristic: [consonants] + [vowels] + [optional closing consonants]
            const syllableRegex = /[^aeiouy]*[aeiouy]+(?:[^aeiouy]*$|[^aeiouy](?=[^aeiouy]))?/gi;
            let syllables = word.match(syllableRegex) || [word];
            
            // Cleanup: Attach leftovers
            const joined = syllables.join('');
            if (joined.length < word.length) {
                syllables[syllables.length - 1] += word.slice(joined.length);
            }
            return syllables;
        }

        // --- 3. MODEL LOADING ---
        async function loadModels() {
            try {
                const option = { executionProviders: ['wasm'] }; 
                encSession = await ort.InferenceSession.create('./v4-encoder.onnx', option);
                decSession = await ort.InferenceSession.create('./v4-decoder.onnx', option);
                document.getElementById('status').innerText = "Models Loaded! Ready.";
            } catch (e) {
                document.getElementById('status').innerText = "Error: " + e;
            }
        }
        loadModels();

        // --- 4. INFERENCE ---
        async function runInference() {
            const word = document.getElementById('inputText').value.toLowerCase().trim();
            if (!word || !encSession) return;
            
            // A. Display Syllables (Visualization Only)
            const tokens = tokenizeSyllables(word);
            const tokenHtml = tokens.map(t => `<span class="syllable">${t}</span>`).join('');
            document.getElementById('syllableResult').innerHTML = tokenHtml;

            // B. Run ONNX Model (Character-Level)
            document.getElementById('result').innerText = "...";
            try {
                // Encode Chars
                const srcIndices = [1]; 
                for (let char of word) srcIndices.push(VOCAB_DATA.input_char2idx[char] || 3);
                srcIndices.push(2);

                const srcTensor = new ort.Tensor('int64', BigInt64Array.from(srcIndices.map(x => BigInt(x))), [1, srcIndices.length]);
                
                // Encoder
                const encResults = await encSession.run({ src: srcTensor });
                const context = encResults.context;

                // Decoder
                let hidden = context;
                let currTokenIdx = 1n;
                let decodedStr = "";

                for (let i = 0; i < MAX_LEN; i++) {
                    const decResults = await decSession.run({
                        input: new ort.Tensor('int64', BigInt64Array.from([currTokenIdx]), [1]),
                        hidden: hidden,
                        context: context
                    });
                    
                    hidden = decResults.new_hidden;
                    const logits = decResults.prediction.data;

                    let bestIdx = 0;
                    let maxVal = -Infinity;
                    for (let j = 0; j < logits.length; j++) {
                        if (logits[j] > maxVal) { maxVal = logits[j]; bestIdx = j; }
                    }

                    if (bestIdx === 2) break; // EOS
                    if (bestIdx > 3) decodedStr += (VOCAB_DATA.target_idx2char[bestIdx] || "");
                    currTokenIdx = BigInt(bestIdx);
                }

                document.getElementById('result').innerText = decodedStr;

            } catch (e) {
                console.error(e);
                document.getElementById('result').innerText = "Error";
            }
        }
    </script>
</body>
</html>